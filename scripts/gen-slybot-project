#!/usr/bin/env python

import sys
import time

import scrapely.htmlpage as hp

import aile.kernel
import aile.slybot
import aile.ptree

usage = """
{0} url

Will generate a directory 'slybot-project' with the necessary files.
Execute after this:

    slybot crawl aile

Edit the project files to add other urls to be crawled and rename fields, etc...
"""

if __name__ == '__main__':
    if len(sys.argv) != 2:
        sys.exit(usage)
    url = sys.argv[1]

    print 'Downloading URL...',
    t1 = time.clock()
    page = hp.url_to_page(url)
    print 'done ({0}s)'.format(time.clock() - t1)

    print 'Extracting items...',
    t1 = time.clock()
    ie = aile.kernel.ItemExtract(aile.ptree.PageTree(page), separate_descendants=True)
    print 'done ({0}s)'.format(time.clock() - t1)

    print 'Generating slybot project'
    aile.slybot.generate_slybot(ie)
